\chapter{Theory}
\label{cha:theory}

For the search engine we used Lucene because has very good reviews and plenty of
tutorials.  In conclusion, adding a basic search engine for a set of documents
is easy, but making an accurate and efficient mechanism search takes a lot of
time and effort.

% --------------------------------------------------------------------------- %
% Indexing
% --------------------------------------------------------------------------- %
\section{Indexing}
\label{sec:indexing}

Lucene work with Document objects, each Document have Fields, each Field is
analyzed differently, for instance: a TextField is for content we want tokenized
(the description part of the ICD-10 codes), and StringField is for content we
don't want tokenized (the ICD-10 codes).\\
\\
There are two main parts in the indexing process:

\begin{itemize}
\item The Analyzer extracts tokens out of text to be indexed.

\item The IndexWriter is a key component in the indexing process, is the one
			that adds documents to the index.
\end{itemize}


% --------------------------------------------------------------------------- %
% Scoring
% --------------------------------------------------------------------------- %
% TODO typeset math equations
\section{Scoring}
\label{sec:scoring}
% TODO VSM footnote:
The documents are chosen by a Boolean Model and are scored by a \emph{Vector
Space Model} (VSM)\footnotemark[1]. Lucene uses the boolean model to first
narrow down the number of documents that needs to be scored by VSM. The idea
behind the Vector Space Model is the more times a query term appears in a
document compared to the total number of times the term appears in all the
documents in the documents collection, the more relevant is that document.\\
\\
The similarity in Lucene is calculated by:
\[
	\opn{cosine-similarity}(q,d) = \frac{V(q) \cdot V(d)} {|V(q)||V(d)|}
\]
%
Where \(V(q) \cdot V(d)\) is the \emph{dot product}\footnotemark[2]
(intersection) of the weighted vectors, and \(|V(q)|\) and \(|V(d)|\) are their
\emph{Euclidean norms}\footnotemark[3].\\
\\
For practical reasons the real formula that Lucene uses is:
%
\begin{equation*}
\begin{split}
	\opn{score}(q,d) = & \opn{coord}(q,d) \cdot \opn{queryNorm}(q) \\
	                   & \cdot \sum_{t \opn{in} q} (
	                             \opn{tf}(t\opn{in}d) \cdot
	                             \opn{idf}(t)^{2} \cdot
	                             \opn{t.getBoost}() \cdot
	                             \opn{norm}(t,d)
	                           )
\end{split}
\end{equation*}
%
\begin{description}

\item[\(tf(t\opn{in}d)\)]
correlates to the terms frequency, defined as the number of times term \(t\)
appears in the currently scored document \(d\).

\item[\(\opn{idf}(t)\)]
stands for Inverse Document Frequency.
\[
	\opn{idf}(t) = 1 + \log(\frac{numDocs}{docFreq + 1})
\]

\item[\(\opn{coord}(q,d)\)]
is a score factor based on how many of the query terms are found in the
specified document.

\item[\(\opn{queryNorm}(q)\)]
is a normalizing factor, doesnâ€™t affect to the ranking.

\item[\(\opn{t.getBoost}()\)]
is a search time boost of term t in the query q.

\item[\(\opn{norm}(t,d)\)]
encapsulates a few (indexing time) boost and length factors.

\end{description}


\footnotetext[1]{\url{http://en.wikipedia.org/wiki/Vector\_Space\_Model}}
\footnotetext[2]{\url{http://en.wikipedia.org/wiki/Dot\_product}}
\footnotetext[3]{\url{http://en.wikipedia.org/wiki/Euclidean\_norm\#Euclidean\_norm}}

% vim: set ts=2 sw=2 tw=80:
